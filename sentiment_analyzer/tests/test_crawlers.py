"""
çˆ¬è™«æ¨¡å—æµ‹è¯•

æµ‹è¯•é™æµå™¨ã€ä»£ç†æ± ã€å¸ƒéš†è¿‡æ»¤å™¨å’Œæ•°æ®æ¸…æ´—åŠŸèƒ½ã€‚
"""

import asyncio
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

from sentiment_analyzer.crawlers.rate_limiter import TokenBucket, RateLimit, MultiRateLimiter
from sentiment_analyzer.crawlers.proxy_pool import ProxyPool, ProxyInfo, ProxyStrategy
from sentiment_analyzer.crawlers.bloom_filter import BloomFilter, ScalableBloomFilter
from sentiment_analyzer.crawlers.cleaner import DataCleaner, CleanedContent, create_default_cleaner, create_strict_cleaner


class TestTokenBucket:
    """ä»¤ç‰Œæ¡¶æµ‹è¯•"""

    def test_token_bucket_initialization(self):
        """æµ‹è¯•ä»¤ç‰Œæ¡¶åˆå§‹åŒ–"""
        bucket = TokenBucket(rate=10, capacity=100)
        assert bucket.rate == 10
        assert bucket.capacity == 100
        assert bucket.tokens == 100

    def test_token_bucket_invalid_rate(self):
        """æµ‹è¯•æ— æ•ˆé€Ÿç‡"""
        with pytest.raises(ValueError):
            TokenBucket(rate=0, capacity=100)
        with pytest.raises(ValueError):
            TokenBucket(rate=-1, capacity=100)

    def test_token_bucket_invalid_capacity(self):
        """æµ‹è¯•æ— æ•ˆå®¹é‡"""
        with pytest.raises(ValueError):
            TokenBucket(rate=10, capacity=0)
        with pytest.raises(ValueError):
            TokenBucket(rate=10, capacity=-1)

    def test_try_acquire_success(self):
        """æµ‹è¯•æˆåŠŸè·å–ä»¤ç‰Œ"""
        bucket = TokenBucket(rate=10, capacity=100)
        result = bucket.try_acquire(5)
        assert result is True
        assert bucket.available == 95

    def test_try_acquire_insufficient_tokens(self):
        """æµ‹è¯•ä»¤ç‰Œä¸è¶³"""
        bucket = TokenBucket(rate=10, capacity=100)
        bucket.tokens = 3
        result = bucket.try_acquire(5)
        assert result is False

    def test_try_acquire_exceed_capacity(self):
        """æµ‹è¯•è¯·æ±‚æ•°è¶…è¿‡å®¹é‡"""
        bucket = TokenBucket(rate=10, capacity=100)
        with pytest.raises(ValueError):
            bucket.try_acquire(150)

    @pytest.mark.asyncio
    async def test_acquire_blocking(self):
        """æµ‹è¯•é˜»å¡å¼è·å–ä»¤ç‰Œ"""
        bucket = TokenBucket(rate=100, capacity=10)
        bucket.tokens = 0
        
        start_time = asyncio.get_event_loop().time()
        result = await bucket.acquire(1)
        elapsed = asyncio.get_event_loop().time() - start_time
        
        assert result is True
        assert elapsed >= 0.01

    def test_wait_time_calculation(self):
        """æµ‹è¯•ç­‰å¾…æ—¶é—´è®¡ç®—"""
        bucket = TokenBucket(rate=10, capacity=100)
        bucket.tokens = 5
        wait_time = bucket.wait_time(15)
        assert wait_time == 1.0

    def test_wait_time_sufficient_tokens(self):
        """æµ‹è¯•ä»¤ç‰Œå……è¶³æ—¶çš„ç­‰å¾…æ—¶é—´"""
        bucket = TokenBucket(rate=10, capacity=100)
        bucket.tokens = 50
        wait_time = bucket.wait_time(10)
        assert wait_time == 0.0

    def test_reset(self):
        """æµ‹è¯•é‡ç½®ä»¤ç‰Œæ¡¶"""
        bucket = TokenBucket(rate=10, capacity=100)
        bucket.tokens = 10
        bucket.reset()
        assert bucket.tokens == 100

    def test_available_property(self):
        """æµ‹è¯•å¯ç”¨ä»¤ç‰Œå±æ€§"""
        bucket = TokenBucket(rate=10, capacity=100)
        bucket.tokens = 50
        assert bucket.available == 50


class TestRateLimit:
    """å•çº§é™æµé…ç½®æµ‹è¯•"""

    def test_rate_limit_initialization(self):
        """æµ‹è¯•é™æµé…ç½®åˆå§‹åŒ–"""
        rate_limit = RateLimit(period=60, limit=100)
        assert rate_limit.period == 60
        assert rate_limit.limit == 100
        assert rate_limit.bucket is not None

    @pytest.mark.asyncio
    async def test_rate_limit_acquire(self):
        """æµ‹è¯•é™æµé…ç½®è·å–ä»¤ç‰Œ"""
        rate_limit = RateLimit(period=1, limit=10)
        result = await rate_limit.acquire(1)
        assert result is True

    def test_rate_limit_try_acquire(self):
        """æµ‹è¯•é™æµé…ç½®éé˜»å¡è·å–"""
        rate_limit = RateLimit(period=1, limit=10)
        result = rate_limit.try_acquire(1)
        assert result is True


class TestMultiRateLimiter:
    """å¤šçº§é™æµå™¨æµ‹è¯•"""

    def test_add_limit(self):
        """æµ‹è¯•æ·»åŠ é™æµçº§åˆ«"""
        limiter = MultiRateLimiter()
        limiter.add_limit(period=1, limit=10)
        limiter.add_limit(period=60, limit=100)
        assert len(limiter._limits) == 2

    def test_set_per_second(self):
        """æµ‹è¯•è®¾ç½®æ¯ç§’é™åˆ¶"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10)
        assert len(limiter._limits) == 1
        assert limiter._limits[0].period == 1.0

    def test_set_per_minute(self):
        """æµ‹è¯•è®¾ç½®æ¯åˆ†é’Ÿé™åˆ¶"""
        limiter = MultiRateLimiter()
        limiter.set_per_minute(100)
        assert len(limiter._limits) == 1
        assert limiter._limits[0].period == 60.0

    def test_set_per_hour(self):
        """æµ‹è¯•è®¾ç½®æ¯å°æ—¶é™åˆ¶"""
        limiter = MultiRateLimiter()
        limiter.set_per_hour(1000)
        assert len(limiter._limits) == 1
        assert limiter._limits[0].period == 3600.0

    def test_chain_calls(self):
        """æµ‹è¯•é“¾å¼è°ƒç”¨"""
        limiter = MultiRateLimiter()
        result = limiter.set_per_second(10).set_per_minute(100).set_per_hour(1000)
        assert result is limiter
        assert len(limiter._limits) == 3

    @pytest.mark.asyncio
    async def test_acquire_all_levels(self):
        """æµ‹è¯•é€šè¿‡æ‰€æœ‰çº§åˆ«é™æµ"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(100).set_per_minute(1000)
        await limiter.acquire(1)
        assert limiter._limits[0].bucket.available == 99
        assert limiter._limits[1].bucket.available == 999

    def test_try_acquire_success(self):
        """æµ‹è¯•éé˜»å¡è·å–æˆåŠŸ"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10).set_per_minute(100)
        result = limiter.try_acquire(1)
        assert result is True

    def test_try_acquire_one_level_fails(self):
        """æµ‹è¯•æŸä¸€çº§é™æµå¤±è´¥"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10)
        limiter._limits[0].bucket.tokens = 0
        result = limiter.try_acquire(1)
        assert result is False

    def test_wait_time(self):
        """æµ‹è¯•ç­‰å¾…æ—¶é—´è®¡ç®—"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10)
        limiter._limits[0].bucket.tokens = 0
        wait_time = limiter.wait_time(1)
        assert wait_time > 0

    def test_update_rate(self):
        """æµ‹è¯•æ›´æ–°é™æµé€Ÿç‡"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10)
        result = limiter.update_rate(1.0, 20)
        assert result is True
        assert limiter._limits[0].limit == 20

    def test_update_rate_not_found(self):
        """æµ‹è¯•æ›´æ–°ä¸å­˜åœ¨çš„é™æµçº§åˆ«"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10)
        result = limiter.update_rate(999, 20)
        assert result is False

    def test_get_status(self):
        """æµ‹è¯•è·å–é™æµå™¨çŠ¶æ€"""
        limiter = MultiRateLimiter()
        limiter.set_per_second(10).set_per_minute(100)
        status = limiter.get_status()
        assert "level_0" in status
        assert "level_1" in status
        assert status["level_0"]["period"] == 1.0
        assert status["level_1"]["period"] == 60.0

    def test_from_config(self):
        """æµ‹è¯•ä»é…ç½®åˆ›å»ºé™æµå™¨"""
        limiter = MultiRateLimiter.from_config(
            requests_per_second=10,
            requests_per_minute=100,
            requests_per_hour=1000
        )
        assert len(limiter._limits) == 3


class TestProxyInfo:
    """ä»£ç†ä¿¡æ¯æµ‹è¯•"""

    def test_proxy_info_initialization(self):
        """æµ‹è¯•ä»£ç†ä¿¡æ¯åˆå§‹åŒ–"""
        proxy = ProxyInfo(url="http://proxy:8080")
        assert proxy.url == "http://proxy:8080"
        assert proxy.protocol == "http"
        assert proxy.quality_score == 50.0

    def test_success_rate_no_requests(self):
        """æµ‹è¯•æ— è¯·æ±‚æ—¶çš„æˆåŠŸç‡"""
        proxy = ProxyInfo(url="http://proxy:8080")
        assert proxy.success_rate == 1.0

    def test_success_rate_with_requests(self):
        """æµ‹è¯•æœ‰è¯·æ±‚æ—¶çš„æˆåŠŸç‡"""
        proxy = ProxyInfo(url="http://proxy:8080", success_count=8, failure_count=2)
        assert proxy.success_rate == 0.8

    def test_total_requests(self):
        """æµ‹è¯•æ€»è¯·æ±‚æ•°"""
        proxy = ProxyInfo(url="http://proxy:8080", success_count=8, failure_count=2)
        assert proxy.total_requests == 10

    def test_is_healthy_few_requests(self):
        """æµ‹è¯•è¯·æ±‚æ•°å°‘æ—¶åˆ¤æ–­å¥åº·"""
        proxy = ProxyInfo(url="http://proxy:8080", success_count=2, failure_count=1)
        assert proxy.is_healthy is True

    def test_is_healthy_good_proxy(self):
        """æµ‹è¯•å¥åº·ä»£ç†"""
        proxy = ProxyInfo(url="http://proxy:8080", success_count=8, failure_count=2, quality_score=50)
        assert proxy.is_healthy is True

    def test_is_healthy_unhealthy_proxy(self):
        """æµ‹è¯•ä¸å¥åº·ä»£ç†"""
        proxy = ProxyInfo(url="http://proxy:8080", success_count=2, failure_count=8, quality_score=50)
        assert proxy.is_healthy is False

    def test_weight_calculation(self):
        """æµ‹è¯•æƒé‡è®¡ç®—"""
        proxy = ProxyInfo(
            url="http://proxy:8080",
            quality_score=80,
            success_count=9,
            failure_count=1,
            avg_response_time=0.5
        )
        weight = proxy.weight
        assert 0 < weight <= 1

    def test_to_dict(self):
        """æµ‹è¯•è½¬æ¢ä¸ºå­—å…¸"""
        proxy = ProxyInfo(url="http://proxy:8080", country="US")
        data = proxy.to_dict()
        assert data["url"] == "http://proxy:8080"
        assert data["country"] == "US"


class TestProxyPool:
    """ä»£ç†æ± æµ‹è¯•"""

    def test_add_proxy(self):
        """æµ‹è¯•æ·»åŠ ä»£ç†"""
        pool = ProxyPool()
        proxy = ProxyInfo(url="http://proxy:8080")
        result = pool.add_proxy(proxy)
        assert result is True
        assert len(pool) == 1

    def test_add_proxy_empty_url(self):
        """æµ‹è¯•æ·»åŠ ç©ºURLä»£ç†"""
        pool = ProxyPool()
        proxy = ProxyInfo(url="")
        result = pool.add_proxy(proxy)
        assert result is False

    def test_add_proxies_batch(self):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ ä»£ç†"""
        pool = ProxyPool()
        proxies = [
            ProxyInfo(url="http://proxy1:8080"),
            ProxyInfo(url="http://proxy2:8080"),
            ProxyInfo(url="http://proxy3:8080"),
        ]
        count = pool.add_proxies(proxies)
        assert count == 3
        assert len(pool) == 3

    def test_remove_proxy(self):
        """æµ‹è¯•ç§»é™¤ä»£ç†"""
        pool = ProxyPool()
        proxy = ProxyInfo(url="http://proxy:8080")
        pool.add_proxy(proxy)
        result = pool.remove_proxy("http://proxy:8080")
        assert result is True
        assert len(pool) == 0

    def test_remove_proxy_not_found(self):
        """æµ‹è¯•ç§»é™¤ä¸å­˜åœ¨çš„ä»£ç†"""
        pool = ProxyPool()
        result = pool.remove_proxy("http://nonexistent:8080")
        assert result is False

    @pytest.mark.asyncio
    async def test_get_proxy_random(self):
        """æµ‹è¯•éšæœºè·å–ä»£ç†"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080"),
            ProxyInfo(url="http://proxy2:8080"),
        ])
        proxy = await pool.get_proxy(strategy=ProxyStrategy.RANDOM)
        assert proxy is not None
        assert proxy.url in ["http://proxy1:8080", "http://proxy2:8080"]

    @pytest.mark.asyncio
    async def test_get_proxy_weighted(self):
        """æµ‹è¯•åŠ æƒè·å–ä»£ç†"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080", quality_score=90),
            ProxyInfo(url="http://proxy2:8080", quality_score=50),
        ])
        proxy = await pool.get_proxy(strategy=ProxyStrategy.WEIGHTED)
        assert proxy is not None

    @pytest.mark.asyncio
    async def test_get_proxy_round_robin(self):
        """æµ‹è¯•è½®è¯¢è·å–ä»£ç†"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080"),
            ProxyInfo(url="http://proxy2:8080"),
        ])
        proxy1 = await pool.get_proxy(strategy=ProxyStrategy.ROUND_ROBIN)
        proxy2 = await pool.get_proxy(strategy=ProxyStrategy.ROUND_ROBIN)
        assert proxy1.url != proxy2.url

    @pytest.mark.asyncio
    async def test_get_proxy_least_used(self):
        """æµ‹è¯•æœ€å°‘ä½¿ç”¨è·å–ä»£ç†"""
        pool = ProxyPool()
        proxy1 = ProxyInfo(url="http://proxy1:8080", success_count=10)
        proxy2 = ProxyInfo(url="http://proxy2:8080", success_count=2)
        pool.add_proxies([proxy1, proxy2])
        proxy = await pool.get_proxy(strategy=ProxyStrategy.LEAST_USED)
        assert proxy.url == "http://proxy2:8080"

    @pytest.mark.asyncio
    async def test_get_proxy_by_country(self):
        """æµ‹è¯•æŒ‰å›½å®¶è·å–ä»£ç†"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080", country="US"),
            ProxyInfo(url="http://proxy2:8080", country="CN"),
        ])
        proxy = await pool.get_proxy(strategy=ProxyStrategy.GEO, country="US")
        assert proxy is not None
        assert proxy.country == "US"

    @pytest.mark.asyncio
    async def test_get_proxy_empty_pool(self):
        """æµ‹è¯•ç©ºä»£ç†æ± è·å–"""
        pool = ProxyPool()
        proxy = await pool.get_proxy()
        assert proxy is None

    def test_report_success(self):
        """æµ‹è¯•æŠ¥å‘ŠæˆåŠŸ"""
        pool = ProxyPool()
        proxy = ProxyInfo(url="http://proxy:8080")
        pool.add_proxy(proxy)
        pool.report_success(proxy, response_time=0.5)
        stored = pool._proxies["http://proxy:8080"]
        assert stored.success_count == 1
        assert stored.avg_response_time == 0.5

    def test_report_failure(self):
        """æµ‹è¯•æŠ¥å‘Šå¤±è´¥"""
        pool = ProxyPool()
        proxy = ProxyInfo(url="http://proxy:8080")
        pool.add_proxy(proxy)
        pool.report_failure(proxy)
        stored = pool._proxies["http://proxy:8080"]
        assert stored.failure_count == 1
        assert stored.quality_score < 50

    @pytest.mark.asyncio
    async def test_health_check(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080", success_count=8, failure_count=2),
            ProxyInfo(url="http://proxy2:8080", success_count=2, failure_count=8),
        ])
        result = await pool.health_check()
        assert result["total"] == 2
        assert result["healthy"] == 1
        assert result["unhealthy"] == 1

    def test_get_stats(self):
        """æµ‹è¯•è·å–ç»Ÿè®¡ä¿¡æ¯"""
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080", quality_score=80, country="US"),
            ProxyInfo(url="http://proxy2:8080", quality_score=60, country="CN"),
        ])
        stats = pool.get_stats()
        assert stats["total"] == 2
        assert stats["avg_quality"] == 70.0
        assert set(stats["countries"]) == {"US", "CN"}

    def test_clear(self):
        """æµ‹è¯•æ¸…ç©ºä»£ç†æ± """
        pool = ProxyPool()
        pool.add_proxies([
            ProxyInfo(url="http://proxy1:8080"),
            ProxyInfo(url="http://proxy2:8080"),
        ])
        pool.clear()
        assert len(pool) == 0

    def test_contains(self):
        """æµ‹è¯•ä»£ç†æ˜¯å¦å­˜åœ¨"""
        pool = ProxyPool()
        pool.add_proxy(ProxyInfo(url="http://proxy:8080"))
        assert "http://proxy:8080" in pool
        assert "http://nonexistent:8080" not in pool


class TestBloomFilter:
    """å¸ƒéš†è¿‡æ»¤å™¨æµ‹è¯•"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        assert bf.capacity == 1000
        assert bf.error_rate == 0.01
        assert bf.element_count == 0

    def test_invalid_error_rate(self):
        """æµ‹è¯•æ— æ•ˆé”™è¯¯ç‡"""
        with pytest.raises(ValueError):
            BloomFilter(capacity=1000, error_rate=0)
        with pytest.raises(ValueError):
            BloomFilter(capacity=1000, error_rate=1)

    def test_invalid_capacity(self):
        """æµ‹è¯•æ— æ•ˆå®¹é‡"""
        with pytest.raises(ValueError):
            BloomFilter(capacity=0, error_rate=0.01)

    def test_add_and_contains(self):
        """æµ‹è¯•æ·»åŠ å’ŒåŒ…å«æ£€æŸ¥"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        bf.add("test_item")
        assert "test_item" in bf
        assert "nonexistent" not in bf

    def test_add_multiple_items(self):
        """æµ‹è¯•æ·»åŠ å¤šä¸ªå…ƒç´ """
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        items = [f"item_{i}" for i in range(100)]
        for item in items:
            bf.add(item)
        
        for item in items:
            assert item in bf
        
        assert len(bf) == 100

    def test_union(self):
        """æµ‹è¯•å¹¶é›†æ“ä½œ"""
        bf1 = BloomFilter(capacity=1000, error_rate=0.01)
        bf2 = BloomFilter(capacity=1000, error_rate=0.01)
        
        bf1.add("item1")
        bf2.add("item2")
        
        union = bf1.union(bf2)
        assert "item1" in union
        assert "item2" in union

    def test_union_different_sizes(self):
        """æµ‹è¯•ä¸åŒå¤§å°çš„å¹¶é›†"""
        bf1 = BloomFilter(capacity=1000, error_rate=0.01)
        bf2 = BloomFilter(capacity=2000, error_rate=0.01)
        
        with pytest.raises(ValueError):
            bf1.union(bf2)

    def test_inplace_union(self):
        """æµ‹è¯•åŸåœ°å¹¶é›†æ“ä½œ"""
        bf1 = BloomFilter(capacity=1000, error_rate=0.01)
        bf2 = BloomFilter(capacity=1000, error_rate=0.01)
        
        bf1.add("item1")
        bf2.add("item2")
        
        bf1 |= bf2
        assert "item1" in bf1
        assert "item2" in bf1

    def test_save_and_load(self):
        """æµ‹è¯•ä¿å­˜å’ŒåŠ è½½"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        for i in range(100):
            bf.add(f"item_{i}")
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".bloom") as f:
            temp_path = Path(f.name)
        
        try:
            bf.save(temp_path)
            loaded = BloomFilter.load(temp_path)
            
            assert loaded.capacity == bf.capacity
            assert loaded.element_count == bf.element_count
            
            for i in range(100):
                assert f"item_{i}" in loaded
        finally:
            if temp_path.exists():
                temp_path.unlink()

    def test_clear(self):
        """æµ‹è¯•æ¸…ç©ºè¿‡æ»¤å™¨"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        bf.add("item1")
        bf.add("item2")
        bf.clear()
        assert bf.element_count == 0
        assert "item1" not in bf

    def test_load_factor(self):
        """æµ‹è¯•è´Ÿè½½å› å­"""
        bf = BloomFilter(capacity=100, error_rate=0.01)
        assert bf.load_factor == 0.0
        
        for i in range(50):
            bf.add(f"item_{i}")
        assert bf.load_factor == 0.5

    def test_estimated_false_positive_rate(self):
        """æµ‹è¯•ä¼°è®¡çš„å‡é˜³æ€§ç‡"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        assert bf.estimated_false_positive_rate == 0.0
        
        for i in range(500):
            bf.add(f"item_{i}")
        assert bf.estimated_false_positive_rate > 0

    def test_get_info(self):
        """æµ‹è¯•è·å–è¿‡æ»¤å™¨ä¿¡æ¯"""
        bf = BloomFilter(capacity=1000, error_rate=0.01)
        info = bf.get_info()
        assert "capacity" in info
        assert "error_rate" in info
        assert "bit_size" in info
        assert "hash_count" in info


class TestScalableBloomFilter:
    """å¯æ‰©å±•å¸ƒéš†è¿‡æ»¤å™¨æµ‹è¯•"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        assert sbf._initial_capacity == 100
        assert len(sbf._filters) == 1

    def test_add_and_contains(self):
        """æµ‹è¯•æ·»åŠ å’ŒåŒ…å«æ£€æŸ¥"""
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        sbf.add("test_item")
        assert "test_item" in sbf
        assert "nonexistent" not in sbf

    def test_auto_expand(self):
        """æµ‹è¯•è‡ªåŠ¨æ‰©å±•"""
        sbf = ScalableBloomFilter(initial_capacity=10, error_rate=0.01)
        
        for i in range(50):
            sbf.add(f"item_{i}")
        
        assert len(sbf._filters) > 1
        assert len(sbf) == 50

    def test_add_many(self):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ """
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        items = [f"item_{i}" for i in range(100)]
        sbf.add_many(items)
        assert len(sbf) == 100

    def test_add_duplicate(self):
        """æµ‹è¯•æ·»åŠ é‡å¤å…ƒç´ """
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        sbf.add("item1")
        sbf.add("item1")
        assert len(sbf) == 1

    def test_save_and_load(self):
        """æµ‹è¯•ä¿å­˜å’ŒåŠ è½½"""
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        for i in range(200):
            sbf.add(f"item_{i}")
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".sbf") as f:
            temp_path = Path(f.name)
        
        try:
            sbf.save(temp_path)
            loaded = ScalableBloomFilter.load(temp_path)
            
            assert len(loaded) == len(sbf)
            for i in range(200):
                assert f"item_{i}" in loaded
        finally:
            if temp_path.exists():
                temp_path.unlink()

    def test_clear(self):
        """æµ‹è¯•æ¸…ç©ºè¿‡æ»¤å™¨"""
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        sbf.add("item1")
        sbf.add("item2")
        sbf.clear()
        assert len(sbf) == 0
        assert "item1" not in sbf

    def test_get_info(self):
        """æµ‹è¯•è·å–è¿‡æ»¤å™¨ä¿¡æ¯"""
        sbf = ScalableBloomFilter(initial_capacity=100, error_rate=0.01)
        info = sbf.get_info()
        assert "initial_capacity" in info
        assert "error_rate" in info
        assert "element_count" in info
        assert "filter_count" in info


class TestDataCleaner:
    """æ•°æ®æ¸…æ´—æµ‹è¯•"""

    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        cleaner = DataCleaner()
        assert cleaner.remove_html is True
        assert cleaner.remove_urls is False

    def test_clean_text_basic(self):
        """æµ‹è¯•åŸºæœ¬æ–‡æœ¬æ¸…æ´—"""
        cleaner = DataCleaner()
        text = "  Hello   World  "
        result = cleaner.clean_text(text)
        assert result == "Hello World"

    def test_clean_text_html(self):
        """æµ‹è¯•HTMLæ¸…æ´—"""
        cleaner = DataCleaner(remove_html=True)
        text = "<p>Hello <b>World</b></p>"
        result = cleaner.clean_text(text)
        assert "<p>" not in result
        assert "<b>" not in result

    def test_clean_text_urls(self):
        """æµ‹è¯•URLæ¸…æ´—"""
        cleaner = DataCleaner(remove_urls=True)
        text = "Visit https://example.com for more info"
        result = cleaner.clean_text(text)
        assert "https://example.com" not in result

    def test_clean_text_mentions(self):
        """æµ‹è¯•æåŠæ¸…æ´—"""
        cleaner = DataCleaner(remove_mentions=True)
        text = "Hello @user1 and @user2"
        result = cleaner.clean_text(text)
        assert "@user1" not in result
        assert "@user2" not in result

    def test_clean_text_hashtags(self):
        """æµ‹è¯•è¯é¢˜æ ‡ç­¾æ¸…æ´—"""
        cleaner = DataCleaner(remove_hashtags=True)
        text = "This is #test #example"
        result = cleaner.clean_text(text)
        assert "#test" not in result
        assert "#example" not in result

    def test_clean_text_lowercase(self):
        """æµ‹è¯•å°å†™è½¬æ¢"""
        cleaner = DataCleaner(lowercase=True)
        text = "Hello World"
        result = cleaner.clean_text(text)
        assert result == "hello world"

    def test_clean_text_emoji(self):
        """æµ‹è¯•è¡¨æƒ…ç¬¦å·æ¸…æ´—"""
        cleaner = DataCleaner(remove_emoji=True)
        text = "Hello ğŸ˜€ World ğŸ‰"
        result = cleaner.clean_text(text)
        assert "ğŸ˜€" not in result
        assert "ğŸ‰" not in result

    def test_clean_text_max_length(self):
        """æµ‹è¯•æœ€å¤§é•¿åº¦é™åˆ¶"""
        cleaner = DataCleaner(max_length=10)
        text = "This is a very long text"
        result = cleaner.clean_text(text)
        assert len(result) == 10

    def test_clean_text_empty(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        cleaner = DataCleaner()
        result = cleaner.clean_text("")
        assert result == ""

    def test_normalize_content(self):
        """æµ‹è¯•å†…å®¹æ ‡å‡†åŒ–"""
        cleaner = DataCleaner()
        content = "Check https://example.com #test @user"
        result = cleaner.normalize_content(content)
        
        assert isinstance(result, CleanedContent)
        assert result.original_length == len(content)
        assert len(result.urls) == 1
        assert len(result.hashtags) == 1
        assert len(result.mentions) == 1

    def test_normalize_content_dict(self):
        """æµ‹è¯•å­—å…¸å†…å®¹æ ‡å‡†åŒ–"""
        cleaner = DataCleaner()
        content = {"text": "Hello World", "extra": "data"}
        result = cleaner.normalize_content(content)
        assert result.text == "Hello World"

    def test_detect_language_chinese(self):
        """æµ‹è¯•ä¸­æ–‡æ£€æµ‹"""
        cleaner = DataCleaner()
        text = "è¿™æ˜¯ä¸€æ®µä¸­æ–‡æ–‡æœ¬"
        lang = cleaner.detect_language(text)
        assert lang == "zh"

    def test_detect_language_english(self):
        """æµ‹è¯•è‹±æ–‡æ£€æµ‹"""
        cleaner = DataCleaner()
        text = "This is an English text"
        lang = cleaner.detect_language(text)
        assert lang == "en"

    def test_detect_language_empty(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬è¯­è¨€æ£€æµ‹"""
        cleaner = DataCleaner()
        lang = cleaner.detect_language("")
        assert lang is None

    def test_extract_urls(self):
        """æµ‹è¯•URLæå–"""
        cleaner = DataCleaner()
        text = "Visit https://example.com and http://test.org"
        urls = cleaner.extract_urls(text)
        assert len(urls) == 2

    def test_extract_hashtags(self):
        """æµ‹è¯•è¯é¢˜æ ‡ç­¾æå–"""
        cleaner = DataCleaner()
        text = "This is #test and #example"
        hashtags = cleaner.extract_hashtags(text)
        assert "test" in hashtags
        assert "example" in hashtags

    def test_extract_mentions(self):
        """æµ‹è¯•æåŠæå–"""
        cleaner = DataCleaner()
        text = "Hello @user1 and @user2"
        mentions = cleaner.extract_mentions(text)
        assert "user1" in mentions
        assert "user2" in mentions

    def test_normalize_url(self):
        """æµ‹è¯•URLæ ‡å‡†åŒ–"""
        cleaner = DataCleaner()
        url = "HTTPS://Example.COM/Path/"
        result = cleaner.normalize_url(url)
        assert "https://" in result.lower()
        assert "example.com" in result.lower()

    def test_remove_duplicates(self):
        """æµ‹è¯•å»é‡"""
        cleaner = DataCleaner()
        items = ["a", "b", "a", "c", "b"]
        result = cleaner.remove_duplicates(items)
        assert len(result) == 3
        assert set(result) == {"a", "b", "c"}

    def test_remove_duplicates_dict(self):
        """æµ‹è¯•å­—å…¸å»é‡"""
        cleaner = DataCleaner()
        items = [
            {"id": 1, "name": "a"},
            {"id": 2, "name": "b"},
            {"id": 1, "name": "c"},
        ]
        result = cleaner.remove_duplicates(items, key="id")
        assert len(result) == 2

    def test_clean_batch(self):
        """æµ‹è¯•æ‰¹é‡æ¸…æ´—"""
        cleaner = DataCleaner()
        texts = ["  Hello  ", "  World  ", "  Test  "]
        results = cleaner.clean_batch(texts)
        assert results == ["Hello", "World", "Test"]

    def test_normalize_batch(self):
        """æµ‹è¯•æ‰¹é‡æ ‡å‡†åŒ–"""
        cleaner = DataCleaner()
        contents = ["Hello #test", "World #example"]
        results = cleaner.normalize_batch(contents)
        assert len(results) == 2
        assert all(isinstance(r, CleanedContent) for r in results)

    def test_get_stats(self):
        """æµ‹è¯•è·å–ç»Ÿè®¡ä¿¡æ¯"""
        cleaner = DataCleaner()
        contents = ["Hello World", "Test Content"]
        results = cleaner.normalize_batch(contents)
        stats = cleaner.get_stats(results)
        
        assert stats["total"] == 2
        assert stats["avg_original_length"] > 0

    def test_create_default_cleaner(self):
        """æµ‹è¯•åˆ›å»ºé»˜è®¤æ¸…æ´—å™¨"""
        cleaner = create_default_cleaner()
        assert cleaner.remove_html is True
        assert cleaner.remove_urls is False

    def test_create_strict_cleaner(self):
        """æµ‹è¯•åˆ›å»ºä¸¥æ ¼æ¸…æ´—å™¨"""
        cleaner = create_strict_cleaner()
        assert cleaner.remove_html is True
        assert cleaner.remove_urls is True
        assert cleaner.remove_mentions is True
        assert cleaner.lowercase is True
