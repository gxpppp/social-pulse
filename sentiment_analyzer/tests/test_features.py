"""
ç‰¹å¾æå–æ¨¡å—æµ‹è¯•

æµ‹è¯•æ—¶åºç‰¹å¾ã€å†…å®¹ç‰¹å¾ã€ç‰¹å¾å‘é‡ç­‰åŠŸèƒ½ã€‚
"""

import math
from datetime import datetime, timedelta
from unittest.mock import MagicMock, patch

import numpy as np
import pytest

from ..analysis.features import (
    FeatureExtractor,
    TextFeatures,
    SentimentResult,
    TemporalFeatures,
    ContentFeatures,
    NetworkFeatures,
    MetadataFeatures,
    UserFeatureVector,
)


class TestTextFeatures:
    """æ–‡æœ¬ç‰¹å¾æµ‹è¯•"""

    def test_text_features_creation(self):
        """æµ‹è¯•åˆ›å»ºæ–‡æœ¬ç‰¹å¾"""
        features = TextFeatures(
            word_count=10,
            char_count=50,
            avg_word_length=5.0,
            hashtag_count=2,
            mention_count=1,
            url_count=1,
            emoji_count=3,
            exclamation_count=1,
            question_count=0,
            uppercase_ratio=0.1,
            language="en",
            keywords=["test", "example"],
        )
        
        assert features.word_count == 10
        assert features.char_count == 50
        assert features.language == "en"


class TestSentimentResult:
    """æƒ…æ„Ÿåˆ†æç»“æœæµ‹è¯•"""

    def test_sentiment_result_creation(self):
        """æµ‹è¯•åˆ›å»ºæƒ…æ„Ÿåˆ†æç»“æœ"""
        result = SentimentResult(
            score=0.5,
            label="positive",
            confidence=0.85,
            positive_words=["good", "great"],
            negative_words=[],
        )
        
        assert result.score == 0.5
        assert result.label == "positive"
        assert result.confidence == 0.85


class TestTemporalFeatures:
    """æ—¶åºç‰¹å¾æµ‹è¯•"""

    def test_temporal_features_default_values(self):
        """æµ‹è¯•é»˜è®¤å€¼"""
        features = TemporalFeatures()
        assert features.daily_post_mean == 0.0
        assert features.daily_post_std == 0.0
        assert features.burst_score == 0.0
        assert features.hour_entropy == 0.0

    def test_temporal_features_custom_values(self):
        """æµ‹è¯•è‡ªå®šä¹‰å€¼"""
        features = TemporalFeatures(
            daily_post_mean=5.5,
            daily_post_std=2.3,
            burst_score=1.5,
            hour_entropy=3.2,
            work_hours_ratio=0.6,
            night_activity_ratio=0.1,
            weekend_activity_ratio=0.2,
            autocorrelation=[0.5, 0.3, 0.1],
            avg_response_delay=120.0,
            response_delay_std=60.0,
        )
        
        assert features.daily_post_mean == 5.5
        assert features.autocorrelation == [0.5, 0.3, 0.1]


class TestContentFeatures:
    """å†…å®¹ç‰¹å¾æµ‹è¯•"""

    def test_content_features_default_values(self):
        """æµ‹è¯•é»˜è®¤å€¼"""
        features = ContentFeatures()
        assert features.text_similarity_mean == 0.0
        assert features.topic_entropy == 0.0
        assert features.template_match_ratio == 0.0

    def test_content_features_custom_values(self):
        """æµ‹è¯•è‡ªå®šä¹‰å€¼"""
        features = ContentFeatures(
            text_similarity_mean=0.3,
            text_similarity_std=0.1,
            text_similarity_max=0.8,
            topic_entropy=2.5,
            topic_consistency=0.7,
            sentiment_polarity_mean=0.2,
            sentiment_polarity_std=0.15,
            sentiment_consistency=0.8,
            template_match_ratio=0.1,
            unique_template_count=5,
        )
        
        assert features.text_similarity_mean == 0.3
        assert features.unique_template_count == 5


class TestNetworkFeatures:
    """ç½‘ç»œç‰¹å¾æµ‹è¯•"""

    def test_network_features_default_values(self):
        """æµ‹è¯•é»˜è®¤å€¼"""
        features = NetworkFeatures()
        assert features.degree_centrality == 0.0
        assert features.betweenness_centrality == 0.0
        assert features.community_id == -1

    def test_network_features_custom_values(self):
        """æµ‹è¯•è‡ªå®šä¹‰å€¼"""
        features = NetworkFeatures(
            degree_centrality=0.5,
            betweenness_centrality=0.3,
            eigenvector_centrality=0.2,
            pagerank=0.01,
            clustering_coefficient=0.6,
            community_id=2,
            modularity_contribution=0.05,
        )
        
        assert features.degree_centrality == 0.5
        assert features.community_id == 2


class TestMetadataFeatures:
    """å…ƒæ•°æ®ç‰¹å¾æµ‹è¯•"""

    def test_metadata_features_default_values(self):
        """æµ‹è¯•é»˜è®¤å€¼"""
        features = MetadataFeatures()
        assert features.registration_cluster_score == 0.0
        assert features.profile_completeness == 0.0
        assert features.avatar_hash == ""

    def test_metadata_features_custom_values(self):
        """æµ‹è¯•è‡ªå®šä¹‰å€¼"""
        features = MetadataFeatures(
            registration_cluster_score=0.8,
            profile_completeness=0.6,
            username_pattern_score=0.4,
            username_digit_ratio=0.3,
            avatar_similarity_count=5,
            avatar_hash="abc123",
        )
        
        assert features.registration_cluster_score == 0.8
        assert features.avatar_hash == "abc123"


class TestUserFeatureVector:
    """ç”¨æˆ·ç‰¹å¾å‘é‡æµ‹è¯•"""

    def test_user_feature_vector_creation(self):
        """æµ‹è¯•åˆ›å»ºç”¨æˆ·ç‰¹å¾å‘é‡"""
        vector = UserFeatureVector(user_id="test_user")
        assert vector.user_id == "test_user"
        assert isinstance(vector.temporal_features, TemporalFeatures)
        assert isinstance(vector.content_features, ContentFeatures)

    def test_to_vector_all_features(self):
        """æµ‹è¯•è½¬æ¢ä¸ºå‘é‡ï¼ˆæ‰€æœ‰ç‰¹å¾ï¼‰"""
        vector = UserFeatureVector(
            user_id="test_user",
            raw_features={"f1": 1.0, "f2": 2.0, "f3": 3.0},
        )
        arr = vector.to_vector()
        
        assert len(arr) == 3
        assert list(arr) == [1.0, 2.0, 3.0]

    def test_to_vector_selected_features(self):
        """æµ‹è¯•è½¬æ¢ä¸ºå‘é‡ï¼ˆé€‰æ‹©ç‰¹å¾ï¼‰"""
        vector = UserFeatureVector(
            user_id="test_user",
            raw_features={"f1": 1.0, "f2": 2.0, "f3": 3.0},
        )
        arr = vector.to_vector(feature_names=["f2", "f3"])
        
        assert len(arr) == 2
        assert list(arr) == [2.0, 3.0]

    def test_to_vector_missing_features(self):
        """æµ‹è¯•è½¬æ¢ä¸ºå‘é‡ï¼ˆç¼ºå¤±ç‰¹å¾ï¼‰"""
        vector = UserFeatureVector(
            user_id="test_user",
            raw_features={"f1": 1.0},
        )
        arr = vector.to_vector(feature_names=["f1", "f2", "f3"])
        
        assert len(arr) == 3
        assert list(arr) == [1.0, 0.0, 0.0]

    def test_normalize_no_scaler(self):
        """æµ‹è¯•æ ‡å‡†åŒ–ï¼ˆæ— scalerï¼‰"""
        vector = UserFeatureVector(
            user_id="test_user",
            raw_features={"f1": 10.0, "f2": 20.0, "f3": 30.0},
        )
        normalized = vector.normalize()
        
        assert len(normalized) == 3
        assert all(isinstance(v, float) for v in normalized.values())

    def test_normalize_empty_features(self):
        """æµ‹è¯•æ ‡å‡†åŒ–ï¼ˆç©ºç‰¹å¾ï¼‰"""
        vector = UserFeatureVector(user_id="test_user")
        normalized = vector.normalize()
        
        assert normalized == {}

    def test_select_features(self):
        """æµ‹è¯•ç‰¹å¾é€‰æ‹©"""
        vector = UserFeatureVector(
            user_id="test_user",
            raw_features={"f1": 1.0, "f2": 2.0, "f3": 3.0},
        )
        selected = vector.select_features(["f1", "f3"])
        
        assert selected == {"f1": 1.0, "f3": 3.0}

    def test_get_all_features(self):
        """æµ‹è¯•è·å–æ‰€æœ‰ç‰¹å¾"""
        vector = UserFeatureVector(
            user_id="test_user",
            temporal_features=TemporalFeatures(daily_post_mean=5.0),
            content_features=ContentFeatures(text_similarity_mean=0.5),
        )
        features = vector.get_all_features()
        
        assert "temporal_features.daily_post_mean" in features
        assert "content_features.text_similarity_mean" in features
        assert features["temporal_features.daily_post_mean"] == 5.0


class TestFeatureExtractor:
    """ç‰¹å¾æå–å™¨æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_features_english(self, extractor: FeatureExtractor):
        """æµ‹è¯•æå–è‹±æ–‡æ–‡æœ¬ç‰¹å¾"""
        text = "Hello World! This is a test. #example @user https://example.com"
        features = extractor.extract_features(text)
        
        assert features.word_count > 0
        assert features.char_count == len(text)
        assert features.hashtag_count == 1
        assert features.mention_count == 1
        assert features.url_count == 1

    def test_extract_features_chinese(self, extractor: FeatureExtractor):
        """æµ‹è¯•æå–ä¸­æ–‡æ–‡æœ¬ç‰¹å¾"""
        text = "è¿™æ˜¯ä¸€æ®µä¸­æ–‡æµ‹è¯•æ–‡æœ¬ã€‚#æµ‹è¯• @ç”¨æˆ·"
        features = extractor.extract_features(text)
        
        assert features.word_count > 0
        assert features.language in ["zh", "zh-cn", "unknown"]

    def test_extract_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•æå–ç©ºæ–‡æœ¬ç‰¹å¾"""
        features = extractor.extract_features("")
        assert features.word_count == 0
        assert features.char_count == 0

    def test_extract_features_with_emoji(self, extractor: FeatureExtractor):
        """æµ‹è¯•æå–åŒ…å«è¡¨æƒ…ç¬¦å·çš„æ–‡æœ¬ç‰¹å¾"""
        text = "Hello ğŸ˜€ World ğŸ‰ Test ğŸš€"
        features = extractor.extract_features(text)
        
        assert features.emoji_count >= 3

    def test_analyze_sentiment_positive(self, extractor: FeatureExtractor):
        """æµ‹è¯•åˆ†æç§¯ææƒ…æ„Ÿ"""
        text = "This is great! I love it! Amazing and wonderful!"
        result = extractor.analyze_sentiment(text)
        
        assert result.label in ["positive", "neutral"]
        assert isinstance(result.confidence, float)

    def test_analyze_sentiment_negative(self, extractor: FeatureExtractor):
        """æµ‹è¯•åˆ†ææ¶ˆææƒ…æ„Ÿ"""
        text = "This is terrible! I hate it! Bad and awful!"
        result = extractor.analyze_sentiment(text)
        
        assert result.label in ["negative", "neutral"]
        assert isinstance(result.confidence, float)

    def test_analyze_sentiment_neutral(self, extractor: FeatureExtractor):
        """æµ‹è¯•åˆ†æä¸­æ€§æƒ…æ„Ÿ"""
        text = "The weather is normal today."
        result = extractor.analyze_sentiment(text)
        
        assert result.label in ["positive", "negative", "neutral"]

    def test_extract_batch_features(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ‰¹é‡æå–ç‰¹å¾"""
        texts = ["Hello World", "Test content", "Another text"]
        features = extractor.extract_batch_features(texts)
        
        assert len(features) == 3
        assert all(isinstance(f, TextFeatures) for f in features)

    def test_analyze_batch_sentiment(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ‰¹é‡åˆ†ææƒ…æ„Ÿ"""
        texts = ["Great!", "Terrible!", "Normal."]
        results = extractor.analyze_batch_sentiment(texts)
        
        assert len(results) == 3
        assert all(isinstance(r, SentimentResult) for r in results)


class TestPostFrequencyExtraction:
    """å‘å¸ƒé¢‘ç‡ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_post_frequency_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_post_frequency([])
        assert result["daily_post_mean"] == 0.0
        assert result["daily_post_std"] == 0.0
        assert result["burst_score"] == 0.0

    def test_extract_post_frequency_single_post(self, extractor: FeatureExtractor):
        """æµ‹è¯•å•ä¸ªå¸–å­"""
        posts = [{"posted_at": datetime.utcnow()}]
        result = extractor.extract_post_frequency(posts)
        
        assert result["daily_post_mean"] == 1
        assert result["daily_post_std"] == 0.0

    def test_extract_post_frequency_multiple_posts(self, extractor: FeatureExtractor):
        """æµ‹è¯•å¤šä¸ªå¸–å­"""
        base_time = datetime.utcnow() - timedelta(days=10)
        posts = []
        for i in range(30):
            posts.append({
                "posted_at": base_time + timedelta(days=i // 3),
            })
        
        result = extractor.extract_post_frequency(posts)
        
        assert result["daily_post_mean"] > 0
        assert result["daily_post_std"] >= 0

    def test_extract_post_frequency_string_timestamp(self, extractor: FeatureExtractor):
        """æµ‹è¯•å­—ç¬¦ä¸²æ—¶é—´æˆ³"""
        posts = [
            {"posted_at": "2024-01-01T10:00:00"},
            {"posted_at": "2024-01-01T12:00:00"},
        ]
        result = extractor.extract_post_frequency(posts)
        
        assert result["daily_post_mean"] > 0


class TestTimeDistributionExtraction:
    """æ—¶é—´åˆ†å¸ƒç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_time_distribution_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_time_distribution([])
        assert result["hour_entropy"] == 0.0
        assert result["work_hours_ratio"] == 0.0

    def test_extract_time_distribution_work_hours(self, extractor: FeatureExtractor):
        """æµ‹è¯•å·¥ä½œæ—¶é—´åˆ†å¸ƒ"""
        posts = []
        base_time = datetime(2024, 1, 1, 10, 0, 0)
        for i in range(10):
            posts.append({
                "posted_at": base_time + timedelta(days=i),
            })
        
        result = extractor.extract_time_distribution(posts)
        
        assert result["work_hours_ratio"] > 0

    def test_extract_time_distribution_night_hours(self, extractor: FeatureExtractor):
        """æµ‹è¯•å¤œé—´åˆ†å¸ƒ"""
        posts = []
        base_time = datetime(2024, 1, 1, 2, 0, 0)
        for i in range(10):
            posts.append({
                "posted_at": base_time + timedelta(days=i),
            })
        
        result = extractor.extract_time_distribution(posts)
        
        assert result["night_activity_ratio"] > 0

    def test_extract_time_distribution_weekend(self, extractor: FeatureExtractor):
        """æµ‹è¯•å‘¨æœ«åˆ†å¸ƒ"""
        saturday = datetime(2024, 1, 6, 10, 0, 0)
        posts = []
        for i in range(10):
            posts.append({
                "posted_at": saturday + timedelta(days=i * 7),
            })
        
        result = extractor.extract_time_distribution(posts)
        
        assert result["weekend_activity_ratio"] > 0

    def test_extract_time_distribution_entropy(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ—¶é—´ç†µ"""
        posts = []
        base_time = datetime(2024, 1, 1, 0, 0, 0)
        for hour in range(24):
            posts.append({
                "posted_at": base_time + timedelta(hours=hour),
            })
        
        result = extractor.extract_time_distribution(posts)
        
        assert result["hour_entropy"] > 0


class TestAutocorrelationExtraction:
    """è‡ªç›¸å…³ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_autocorrelation_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_autocorrelation([])
        assert result == []

    def test_extract_autocorrelation_single_post(self, extractor: FeatureExtractor):
        """æµ‹è¯•å•ä¸ªå¸–å­"""
        posts = [{"posted_at": datetime.utcnow()}]
        result = extractor.extract_autocorrelation(posts)
        assert result == []

    def test_extract_autocorrelation_regular_pattern(self, extractor: FeatureExtractor):
        """æµ‹è¯•è§„å¾‹æ¨¡å¼"""
        posts = []
        base_time = datetime(2024, 1, 1, 0, 0, 0)
        for i in range(100):
            posts.append({
                "posted_at": base_time + timedelta(hours=i * 24),
            })
        
        result = extractor.extract_autocorrelation(posts, max_lag=50)
        
        assert len(result) > 0

    def test_extract_autocorrelation_random_pattern(self, extractor: FeatureExtractor):
        """æµ‹è¯•éšæœºæ¨¡å¼"""
        np.random.seed(42)
        posts = []
        base_time = datetime(2024, 1, 1, 0, 0, 0)
        for i in range(100):
            random_hours = np.random.randint(0, 24)
            posts.append({
                "posted_at": base_time + timedelta(hours=i * 24 + random_hours),
            })
        
        result = extractor.extract_autocorrelation(posts, max_lag=50)
        
        assert len(result) > 0


class TestTextSimilarityExtraction:
    """æ–‡æœ¬ç›¸ä¼¼åº¦ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_text_similarity_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_text_similarity([])
        assert result["text_similarity_mean"] == 0.0

    def test_extract_text_similarity_single_post(self, extractor: FeatureExtractor):
        """æµ‹è¯•å•ä¸ªå¸–å­"""
        posts = [{"content": "Single post"}]
        result = extractor.extract_text_similarity(posts)
        assert result["text_similarity_mean"] == 0.0

    def test_extract_text_similarity_similar_content(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç›¸ä¼¼å†…å®¹"""
        posts = [
            {"content": "This is a test post about Python"},
            {"content": "This is a test post about Python"},
            {"content": "This is a test post about Python"},
        ]
        result = extractor.extract_text_similarity(posts)
        
        assert result["text_similarity_mean"] > 0.9

    def test_extract_text_similarity_different_content(self, extractor: FeatureExtractor):
        """æµ‹è¯•ä¸åŒå†…å®¹"""
        posts = [
            {"content": "Python is a programming language"},
            {"content": "The weather is nice today"},
            {"content": "I like to eat pizza"},
        ]
        result = extractor.extract_text_similarity(posts)
        
        assert result["text_similarity_mean"] < 0.5


class TestTopicFeaturesExtraction:
    """è¯é¢˜ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_topic_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_topic_features([])
        assert result["topic_entropy"] == 0.0
        assert result["topic_consistency"] == 0.0

    def test_extract_topic_features_single_post(self, extractor: FeatureExtractor):
        """æµ‹è¯•å•ä¸ªå¸–å­"""
        posts = [{"content": "Single post about Python"}]
        result = extractor.extract_topic_features(posts)
        assert result["topic_entropy"] == 0.0

    def test_extract_topic_features_consistent_topics(self, extractor: FeatureExtractor):
        """æµ‹è¯•ä¸€è‡´è¯é¢˜"""
        posts = [
            {"content": "Python programming is fun"},
            {"content": "Python development tips"},
            {"content": "Learning Python basics"},
        ]
        result = extractor.extract_topic_features(posts, n_topics=2)
        
        assert result["topic_consistency"] > 0


class TestSentimentFeaturesExtraction:
    """æƒ…æ„Ÿç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_sentiment_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_sentiment_features([])
        assert result["sentiment_polarity_mean"] == 0.0

    def test_extract_sentiment_features_positive(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç§¯ææƒ…æ„Ÿ"""
        posts = [
            {"content": "This is great! I love it!"},
            {"content": "Amazing and wonderful!"},
            {"content": "Best experience ever!"},
        ]
        result = extractor.extract_sentiment_features(posts)
        
        assert result["sentiment_polarity_mean"] > 0

    def test_extract_sentiment_features_negative(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ¶ˆææƒ…æ„Ÿ"""
        posts = [
            {"content": "This is terrible! I hate it!"},
            {"content": "Awful and bad!"},
            {"content": "Worst experience ever!"},
        ]
        result = extractor.extract_sentiment_features(posts)
        
        assert result["sentiment_polarity_mean"] < 0


class TestTemplateFeaturesExtraction:
    """æ¨¡æ¿ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_template_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºå¸–å­åˆ—è¡¨"""
        result = extractor.extract_template_features([])
        assert result["template_match_ratio"] == 0.0
        assert result["unique_template_count"] == 0

    def test_extract_template_features_no_template(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ— æ¨¡æ¿"""
        posts = [
            {"content": "Random content about weather"},
            {"content": "Different topic entirely"},
            {"content": "Something completely new"},
        ]
        result = extractor.extract_template_features(posts)
        
        assert result["unique_template_count"] == 3

    def test_extract_template_features_with_template(self, extractor: FeatureExtractor):
        """æµ‹è¯•æœ‰æ¨¡æ¿"""
        template = "Check out this amazing product at"
        posts = [
            {"content": f"{template} https://example1.com"},
            {"content": f"{template} https://example2.com"},
            {"content": f"{template} https://example3.com"},
        ]
        result = extractor.extract_template_features(posts)
        
        assert result["template_match_ratio"] > 0


class TestUsernameFeaturesExtraction:
    """ç”¨æˆ·åç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_username_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºç”¨æˆ·ååˆ—è¡¨"""
        result = extractor.extract_username_features([])
        assert result["username_pattern_score"] == 0.0
        assert result["username_digit_ratio"] == 0.0

    def test_extract_username_features_normal(self, extractor: FeatureExtractor):
        """æµ‹è¯•æ­£å¸¸ç”¨æˆ·å"""
        usernames = ["john_doe", "alice_smith", "bob_jones"]
        result = extractor.extract_username_features(usernames)
        
        assert result["username_digit_ratio"] == 0.0

    def test_extract_username_features_bot_like(self, extractor: FeatureExtractor):
        """æµ‹è¯•æœºå™¨äººé£æ ¼ç”¨æˆ·å"""
        usernames = ["user12345", "user67890", "user11111"]
        result = extractor.extract_username_features(usernames)
        
        assert result["username_pattern_score"] > 0
        assert result["username_digit_ratio"] > 0


class TestTemporalFeaturesExtraction:
    """å®Œæ•´æ—¶åºç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_temporal_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºæ•°æ®"""
        result = extractor.extract_temporal_features([])
        assert isinstance(result, TemporalFeatures)
        assert result.daily_post_mean == 0.0

    def test_extract_temporal_features_complete(self, extractor: FeatureExtractor):
        """æµ‹è¯•å®Œæ•´æ•°æ®"""
        posts = []
        base_time = datetime(2024, 1, 1, 10, 0, 0)
        for i in range(50):
            posts.append({
                "posted_at": base_time + timedelta(hours=i * 6),
            })
        
        interactions = [
            {"response_time": 60},
            {"response_time": 120},
            {"response_time": 90},
        ]
        
        result = extractor.extract_temporal_features(posts, interactions)
        
        assert isinstance(result, TemporalFeatures)
        assert result.daily_post_mean > 0
        assert result.avg_response_delay > 0


class TestContentFeaturesExtraction:
    """å®Œæ•´å†…å®¹ç‰¹å¾æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_content_features_empty(self, extractor: FeatureExtractor):
        """æµ‹è¯•ç©ºæ•°æ®"""
        result = extractor.extract_content_features([])
        assert isinstance(result, ContentFeatures)
        assert result.text_similarity_mean == 0.0

    def test_extract_content_features_complete(self, extractor: FeatureExtractor):
        """æµ‹è¯•å®Œæ•´æ•°æ®"""
        posts = [
            {"content": "Python is great for programming"},
            {"content": "Python has many libraries"},
            {"content": "Learning Python is fun"},
        ]
        
        result = extractor.extract_content_features(posts)
        
        assert isinstance(result, ContentFeatures)
        assert result.text_similarity_mean > 0


class TestUserFeatureVectorExtraction:
    """å®Œæ•´ç”¨æˆ·ç‰¹å¾å‘é‡æå–æµ‹è¯•"""

    @pytest.fixture
    def extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return FeatureExtractor()

    def test_extract_user_feature_vector_minimal(self, extractor: FeatureExtractor):
        """æµ‹è¯•æœ€å°æ•°æ®"""
        result = extractor.extract_user_feature_vector(
            user_id="test_user",
            posts=[],
        )
        
        assert isinstance(result, UserFeatureVector)
        assert result.user_id == "test_user"

    def test_extract_user_feature_vector_complete(self, extractor: FeatureExtractor):
        """æµ‹è¯•å®Œæ•´æ•°æ®"""
        posts = []
        base_time = datetime(2024, 1, 1, 10, 0, 0)
        for i in range(30):
            posts.append({
                "content": f"Test post {i}",
                "posted_at": base_time + timedelta(hours=i * 12),
            })
        
        user_data = {
            "username": "test_user123",
            "display_name": "Test User",
            "bio": "Test bio",
            "avatar_url": "https://example.com/avatar.png",
        }
        
        result = extractor.extract_user_feature_vector(
            user_id="test_user",
            posts=posts,
            user_data=user_data,
        )
        
        assert isinstance(result, UserFeatureVector)
        assert result.user_id == "test_user"
        assert len(result.raw_features) > 0
